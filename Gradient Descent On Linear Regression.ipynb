{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In a simple Linear Regression for which the exquation is y=mx+b, we predict y by finding the slope and the intercept and putting that in the equation for given x. \n",
    "\n",
    "#### How Far Our Predicted is from Actual Point is Found BY taking the error. Here we have Taken Sum of Sq of Errors and our motive is to minimze the error so that it reaches 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeError(b,m,df1):\n",
    "    totalError=0\n",
    "    for i in range(0,df1.shape[0]):\n",
    "        x=df1.loc[i]['x']\n",
    "        y=df1.loc[i]['y']\n",
    "        totalError+=(y-(m*x+b))**2\n",
    "        \n",
    "    return totalError        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent is an Optimization Algorithm that helps us find the parameters of any model so that we get error as less as we can get. \n",
    "\n",
    "#### Since the minimum is found by taking derative so we take derivate of SSE w.r.t (b) and (m) and then we subtract that from our parameter and keep updating like this. \n",
    "\n",
    "# A great Video on Gradient Descent can be found on Youtube By My Idol Mr. Andrew Ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientdescent(b_current,m_current,learningRate,df2):\n",
    "    b_gradient=0\n",
    "    m_gradient=0\n",
    "    N=df2.shape[0]\n",
    "    for i in range(0,df2.shape[0]):\n",
    "        x=df2.loc[i]['x']\n",
    "        y=df2.loc[i]['y']\n",
    "        \n",
    "        b_gradient+= -(2/N) * (y-((m_current*x)+b_current))\n",
    "        m_gradient+= -(2/N) * x * (y-((m_current*x)+b_current))\n",
    "        \n",
    "        return[(b_current -(learningRate * b_gradient)),(m_current -(learningRate * m_gradient))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent Runs for all training Examples in One epcoh(1 run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradientdescent(df3,starting_b,starting_m, learningRate,epochs):\n",
    "    b=starting_b\n",
    "    m=starting_m\n",
    "    for i in range(epochs):\n",
    "        b,m=gradientdescent(b,m,learningRate,df3)\n",
    "    return [b,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv',names=['y','x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.502345</td>\n",
       "      <td>31.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.426804</td>\n",
       "      <td>68.777596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.530358</td>\n",
       "      <td>62.562382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.475640</td>\n",
       "      <td>71.546632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.813208</td>\n",
       "      <td>87.230925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y          x\n",
       "0  32.502345  31.707006\n",
       "1  53.426804  68.777596\n",
       "2  61.530358  62.562382\n",
       "3  47.475640  71.546632\n",
       "4  59.813208  87.230925"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Error 249096.1189080058\n",
      "Running....\n",
      "After Error 78071.31814752745\n"
     ]
    }
   ],
   "source": [
    "b=0\n",
    "m=0\n",
    "epochs=1000\n",
    "learning_rate=0.001\n",
    "\n",
    "print('Initial Error',computeError(b,m,df))\n",
    "print('Running....')\n",
    "\n",
    "[b1,m1]=batch_gradientdescent(df,b,m,learning_rate,epochs)\n",
    "print('After Error',computeError(b1,m1,df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
